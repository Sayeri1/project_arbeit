# -*- coding: utf-8 -*-
"""ocd_project_code (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yF8GyHnjSWkz_05uaq7IvcCr_fynIv68
"""

import pandas as pd
import os
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings('ignore')

import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics

def combine_csv_files(folder_path):
    combined_data = pd.DataFrame()
    file_list = os.listdir(folder_path)
    data_frames = []

    for i, file_name in enumerate(file_list):
        if file_name.endswith('.csv'):
            file_path = os.path.join(folder_path, file_name)
            if i == 0:
                data = pd.read_csv(file_path, header=None)
            else:
                data = pd.read_csv(file_path, header=None,skiprows = 1)
            data_frames.append(data)

    combined_data = pd.concat(data_frames, ignore_index=True)
    return combined_data

#combined_df.to_hdf(f'{folder_path}/combined_df.h5', key='df', mode='w')
combined_df.to_csv(f'{folder_path}/combined_df.csv', index=False)

combined_df.head()

print(len(combined_df))

dataframe = combined_df

print(len(dataframe))

dataframe.columns = dataframe.iloc[0]
dataframe = dataframe[1:]
dataframe.reset_index(drop=True, inplace=True)

dataframe.head()

ignore_unique = pd.to_numeric(dataframe['ignore'], errors='coerce').dropna().astype(int).value_counts().to_dict()
print(ignore_unique)

dataframe_numeric = dataframe.apply(pd.to_numeric, errors='coerce')
new_dataframe = dataframe_numeric[dataframe_numeric['ignore'].eq(0)]
print(len(new_dataframe))

df = new_dataframe[['acc x','acc y','acc z','gyro x','gyro y','gyro z', 'relabeled']]
y = df['relabeled']

df.head()

len(df)

unique_values = df['relabeled'].unique()
print(unique_values)

df_hw = df[df['relabeled'] != 0]
unique_values = df_hw['relabeled'].unique()
print(unique_values)
print(len(df_hw))

df_hw.head()

df_hw.to_csv(f'{folder_path}/df_hw.csv', index=False)

y = df_hw['relabeled']
df_hw.drop(['relabeled'], axis=1, inplace=True)

df_hw.head()

df_hw.shape

X = []
labels = []
window_size = 150
step_size = 150

y

for i in range(0, df_hw.shape[0]-window_size+1, step_size):
  frame = df_hw.iloc[i:i+window_size]
  label = Counter(y.iloc[i:i+window_size]).most_common(1)[0][0]
  X.append(frame)
  labels.append(label)

X_arr = np.array(X)
X_arr.shape

label_arr = np.array(labels)
label_arr.shape

np.unique(label_arr)

X_flattened = X_arr.reshape(X_arr.shape[0], X_arr.shape[1]*X_arr.shape[2])
X_flattened.shape

X_train, X_test, y_train, y_test = train_test_split(X_flattened, label_arr, test_size=0.25, random_state=42, shuffle=True)

#X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)

print(np.unique(y_train))
print(np.unique(y_test))

y_train.shape

classifier = RandomForestClassifier(n_estimators=100)
classifier.fit(X_train, y_train)
y_pred_test = classifier.predict(X_test)

print("F1: ", metrics.f1_score(y_test, y_pred_test, average='weighted'))
print("Precision: ", metrics.precision_score(y_test, y_pred_test, average='weighted'))
print("Recall: ", metrics.recall_score(y_test, y_pred_test, average='weighted'))
print()
print('Confusion Matrix')
print(metrics.confusion_matrix(y_test, y_pred_test))



